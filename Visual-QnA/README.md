# Visual-QnA
Visual Qna using Transformers.

• Utilized combinations of vision transformers (ViT, BEiT, DeiT) and text-based transformers (BERT, RoBERTa)
for image-based question answering. Applied LoRA configuration to optimize model performance.

• Achieved highest validation accuracy of 0.27 with RoBERTa and ViT with LoRA rank of 32 and an average
Wu-Palmer similarity of 0.45.